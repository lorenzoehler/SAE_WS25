### 6) Assess model -------------------------------------------------------
summary(fh_fit)
plot(fh_fit)
### 7) Compare FH vs Direct ----------------------------------------------
# direct vs model-based; CV=TRUE adds coefficient of variation
compare_plot(fh_fit, CV = TRUE, label = "no_title")
compare(fh_fit)
### 8) Extract results ----------------------------------------------------
res <- estimators(fh_fit, MSE = TRUE, CV = TRUE)
# Quick look
head(res)
# Optionally: save results
# Versuch 2.
rm(list = ls())
ls(pattern = "census|pop|frame")
ls()
getwd()
file.exists("../../data_raw/large_files/Persona_CPV-2024.csv")
file.exists("../../data_raw/large_files/Vivienda_CPV-2024.csv")
library(data.table)
census_person <- fread("../../data_raw/large_files/Persona_CPV-2024.csv")
census_house  <- fread("../../data_raw/large_files/Vivienda_CPV-2024.csv")
census_person
census_house
library(dplyr)
census_person <- census_person %>%
mutate(
mun_res_cod = as.character(mun_res_cod),
years_edu   = suppressWarnings(as.numeric(as.character(aestudio)))
)
census_aux_data <- census_person %>%
group_by(mun_res_cod) %>%
summarise(
mean_years_edu = mean(years_edu, na.rm = TRUE),
.groups = "drop"
)
names(head_person)[1:30]
---
#Get Data:
#  Survey-/Sample-Datensatz auf Personenebene, ----------------------------
# dieser liefert:
#den direkten Gebietsschätze
# Varianzen
#setwd("C:/Users/nikla/OneDrive/Dokumente/GitHub/SAE_WS25/data_raw/samples")
#data <- readRDS("data_raw/samples/sample_for_model_building.RDS")
data <- readRDS("sample_for_model_building.RDS")
---
#Get Data:
#  Survey-/Sample-Datensatz auf Personenebene, ----------------------------
# dieser liefert:
#den direkten Gebietsschätze
# Varianzen
#setwd("C:/Users/nikla/OneDrive/Dokumente/GitHub/SAE_WS25/data_raw/samples")
data <- readRDS("data_raw/samples/sample_for_model_building.RDS")
View(data)
#Übersicht
str(data)
head(data)
---
#Get Data:
#  Survey-/Sample-Datensatz auf Personenebene, ----------------------------
# dieser liefert:
#den direkten Gebietsschätze
# Varianzen
#setwd("C:/Users/nikla/OneDrive/Dokumente/GitHub/SAE_WS25/data_raw/samples")
data <- readRDS("data_raw/samples/sample_for_model_building.RDS")
---
#Get Data:
#  Survey-/Sample-Datensatz auf Personenebene, ----------------------------
# dieser liefert:
#den direkten Gebietsschätze
# Varianzen
#setwd("C:/Users/nikla/OneDrive/Dokumente/GitHub/SAE_WS25/data_raw/samples")
data <- readRDS("data_raw/samples/sample_for_model_building.RDS")
---
#Get Data:
#  Survey-/Sample-Datensatz auf Personenebene, ----------------------------
# dieser liefert:
#den direkten Gebietsschätze
# Varianzen
#setwd("C:/Users/nikla/OneDrive/Dokumente/GitHub/SAE_WS25/data_raw/samples")
data <- readRDS("data_raw/samples/sample_for_model_building.RDS")
data <- readRDS("sample_for_model_building.RDS")
# Packages ---------------------------------------------------------------
library(data.table)
library(dplyr)
library(emdi)
# Paths ------------------------------------------------------------------
# Passe diese Pfade an, falls dein Skript woanders liegt:
PATH_SAMPLE_RDS  <- "sample_for_model_building.RDS"
PATH_CENSUS_PER  <- "../../data_raw/large_files/Persona_CPV-2024.csv"
rm(list = ls())
# Packages ---------------------------------------------------------------
library(data.table)
library(dplyr)
library(emdi)
# Paths ------------------------------------------------------------------
# Passe diese Pfade an, falls dein Skript woanders liegt:
PATH_SAMPLE_RDS  <- "sample_for_model_building.RDS"
PATH_CENSUS_PER  <- "../../data_raw/large_files/Persona_CPV-2024.csv"
# 0) Load SAMPLE (Survey) ------------------------------------------------
smp <- readRDS(PATH_SAMPLE_RDS)
# Minimal checks: benötigte Spalten im Sample
stopifnot(all(c("mun_res_cod", "ocu_1d_19") %in% names(smp)))
# Domain-ID & Outcome sauber setzen
smp <- smp %>%
mutate(
mun_res_cod = as.character(mun_res_cod),
ocu_1d_19   = as.numeric(ocu_1d_19)
)
# 1) Direct estimates + vardir (aus dem Sample) --------------------------
# Ziel: pro municipio d
#   Mean_d = direkter Schätzer (z.B. Anteil beschäftigt)
#   Var_Mean_d = approximierte Varianz des direkten Schätzers
direct_estimates <- smp %>%
group_by(mun_res_cod) %>%
summarise(
Mean  = mean(ocu_1d_19, na.rm = TRUE),
n_eff = sum(!is.na(ocu_1d_19)),
Var_Mean = ifelse(n_eff > 0, Mean * (1 - Mean) / n_eff, NA_real_),
.groups = "drop"
)
# Stabilität: keine 0/NA Varianzen zulassen (FH braucht >0)
eps <- 1e-8
direct_estimates <- direct_estimates %>%
mutate(
Var_Mean = ifelse(is.na(Var_Mean), NA_real_, pmax(Var_Mean, eps))
)
# 2) Load CENSUS (Population) --------------------------------------------
# Tipp: Wenn Datei riesig ist, lieber select=... verwenden.
# Wir brauchen hier für X_d nur mun_res_cod + aestudio.
census_person <- fread(
PATH_CENSUS_PER,
select = c("mun_res_cod", "aestudio")
)
# Check: Spalten da?
stopifnot(all(c("mun_res_cod", "aestudio") %in% names(census_person)))
# 3) Census auxiliary variable auf Area-Level ----------------------------
# years_edu aus aestudio, dann mean_years_edu pro municipio
census_person <- census_person %>%
mutate(
mun_res_cod = as.character(mun_res_cod),
years_edu   = suppressWarnings(as.numeric(as.character(aestudio)))
)
census_aux_data <- census_person %>%
group_by(mun_res_cod) %>%
summarise(
mean_years_edu = mean(years_edu, na.rm = TRUE),
.groups = "drop"
)
# 3a) WICHTIG: emdi::fh erlaubt KEINE NAs in Aux-Variablen
# Falls einzelne municipios komplett missing sind -> imputiere global mean
global_mean_edu <- mean(census_aux_data$mean_years_edu, na.rm = TRUE)
census_aux_data <- census_aux_data %>%
mutate(
mean_years_edu = ifelse(is.na(mean_years_edu), global_mean_edu, mean_years_edu)
)
stopifnot(!any(is.na(census_aux_data$mean_years_edu)))
# 4) Combine sample + census aux -----------------------------------------
# pop_data: alle Domains + X_d
# smp_data: Domains + direct + vardir
combined_data <- combine_data(
pop_data = as.data.frame(census_aux_data),
pop_domains = "mun_res_cod",
smp_data = as.data.frame(direct_estimates),
smp_domains = "mun_res_cod"
)
# 5) Fit Fay–Herriot model -----------------------------------------------
# Model: Mean_d = beta0 + beta1 * mean_years_edu_d + u_d + e_d
# e_d Var = Var_Mean_d
fh_fit <- fh(
fixed = Mean ~ mean_years_edu,
vardir = "Var_Mean",
combined_data = combined_data,
domains = "mun_res_cod",
method = "reml",   # meist Standard; "ml" geht auch
MSE = TRUE
)
# 6) Ergebnisse / Diagnose -----------------------------------------------
summary(fh_fit)
# FH vs Direct (Shrinkage sichtbar)
compare_plot(fh_fit, CV = TRUE, label = "no_title")
head(res)
# speichern ? wenn ja ausführen:
write.csv(res, "fh_results_municipio.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(sf)
map <- read_sf("../../data_raw/stanford-xg218hn4313-shapefile/xg218hn4313.shp")
map$count <- 1:nrow(map)
ggplot(map) +
geom_sf(aes(fill = count), color = "grey20", size = 0.1) +
theme_classic()
---
title: "Template Title"
```{r setup, include=FALSE}
# Shapefile laden
bol_muni <- st_read(
"stanford-xg218hn4313-shapefile/xg218hn4313.shp"
)
#MAPPING
################################################
library(sf)
library(dplyr)
library(ggplot2)
# Shapefile laden
bol_muni <- st_read(
"../../data_raw/shape/stanford-xg218hn4313-shapefile/xg218hn4313.shp"
)
names(bol_muni)
nrow(bol_muni)
# welcher Join-Key im Shapefile?
names(bol_muni)
# SAE-Ergebnisse aus emdi
res <- estimators(fh_fit, MSE = TRUE, CV = TRUE)
names(res)
# emdi-Index auspacken
res_df <- res$ind
# anschauen
head(res_df)
names(res_df)
sae_res <- res_df %>%
transmute(
id_3 = as.numeric(domains),   # domains = mun_res_cod
sae  = as.numeric(fh)
)
bol_muni <- st_read(
"stanford-xg218hn4313-shapefile/xg218hn4313.shp"
)
# anschauen
head(res_df)
names(res_df)
# Join-Data vorbereiten
sae_res <- res_df %>%
transmute(
id_3 = as.numeric(Domain),
sae = as.numeric(FH)
)
# Join
map_df <- bol_muni %>%
left_join(sae_res, by = "id_3")
# Check: wie viele gematcht?
sum(!is.na(map_df$sae))
# welcher Join-Key im Shapefile?
names(bol_muni)
range(res_df$Domain, na.rm = TRUE)
range(bol_muni$id_3, na.rm = TRUE)
names(bol_muni)
# 1) Typen & Beispiele anschauen
str(bol_muni$ccn_3)
str(bol_muni$cca_3)
head(bol_muni[, c("id_3", "name_3", "ccn_3", "cca_3")], 10)
# 2) Range/Unique prüfen (ob das nach amtlichen Codes aussieht)
range(as.numeric(bol_muni$ccn_3), na.rm = TRUE)
range(as.numeric(bol_muni$cca_3), na.rm = TRUE)
# 3) Deine Domain-Codes als numeric (0 wird dabei NA, ist ok)
dom_num <- suppressWarnings(as.numeric(res_df$Domain))
# 4) Overlap testen: wie viele Domains sind im Shapefile-Codefeld enthalten?
sum(dom_num %in% as.numeric(bol_muni$ccn_3), na.rm = TRUE)
sum(dom_num %in% as.numeric(bol_muni$cca_3), na.rm = TRUE)
sae_res <- res_df %>%
transmute(
cca_3 = as.numeric(Domain),
sae = as.numeric(FH)
)
map_df <- bol_muni %>%
mutate(cca_3 = as.numeric(cca_3)) %>%
left_join(sae_res, by = "cca_3")
sum(!is.na(map_df$sae))  # sollte jetzt groß sein
ggplot(map_df) +
geom_sf(aes(fill = sae), color = NA) +
scale_fill_viridis_c(na.value = "grey90") +
labs(title = "Bolivien – Fay–Herriot SAE (Municipios)", fill = "FH") +
theme_minimal()
sum(dom_num %in% as.numeric(bol_muni$ccn_3), na.rm = TRUE)
sum(dom_num %in% as.numeric(bol_muni$cca_3), na.rm = TRUE)
##################
list.files(recursive = TRUE, pattern = "match|cross|mun|code|gadm|shape|lookup", ignore.case = TRUE)
##################
names(census_person)
names(census_person)[grepl("name|nom|municip|muni|local", names(census_person), ignore.case = TRUE)]
library(stringi)
# Angenommen die Namensspalte heißt mun_name (bitte dann ersetzen)
crosswalk <- census_person %>%
transmute(
Domain = as.character(mun_res_cod),
name_key = stri_trans_general(toupper(trimws(mun_name)), "Latin-ASCII")
) %>%
distinct() %>%
group_by(Domain) %>%
slice(1) %>%
ungroup()
# Shape Namens-Key
bol_muni <- bol_muni %>%
mutate(name_key = stri_trans_general(toupper(trimws(name_3)), "Latin-ASCII"))
# SAE Ergebnisse
sae_res <- res_df %>%
transmute(
Domain = as.character(Domain),
sae = as.numeric(FH)
)
# Domain -> name -> shape
map_df <- bol_muni %>%
left_join(crosswalk, by = "name_key") %>%
left_join(sae_res, by = "Domain")
sum(!is.na(map_df$sae))
##############
list.files(recursive = TRUE, pattern = "match|cross|mun|code|gadm|shape|lookup", ignore.case = TRUE)
library(data.table)
# Zeigt nur Spaltennamen (lädt keine Datenzeilen)
census_cols <- names(fread("../../data_raw/large_files/Persona_CPV-2024.csv", nrows = 0))
census_cols
# Kandidaten für Namensspalten finden
census_cols[grepl("name|nom|mun|municip|prov|dept|dep|local|nombre", census_cols, ignore.case = TRUE)]
house_cols <- names(fread("../../data_raw/large_files/Vivienda_CPV-2024.csv", nrows = 0))
house_cols
house_cols[grepl("name|nom|mun|municip|prov|dept|dep|local|nombre", house_cols, ignore.case = TRUE)]
bol_muni <- st_read("stanford-xg218hn4313-shapefile/xg218hn4313.shp") %>%
mutate(
name_key = stri_trans_general(toupper(trimws(name_3)), "Latin-ASCII")
)
# 0) Shapefile laden (aus deinem GitHub-Ordner)
bol_muni <- st_read(
"../../data_raw/shape/stanford-xg218hn4313-shapefile/xg218hn4313.shp"
) %>%
mutate(
name_key = stri_trans_general(toupper(trimws(name_3)), "Latin-ASCII")
)
# 1) SAE-Ergebnisse vorbereiten
# res_df hat: Domain, FH, Direct, ...
sae_res <- res_df %>%
transmute(
Domain = as.character(Domain),
sae = as.numeric(FH)
) %>%
# nur plausible Municipio-Codes behalten (typisch 5-6 stellig; "0" / "999999" raus)
filter(grepl("^\\d{5,6}$", Domain), Domain != "0", Domain != "999999")
# 2) Crosswalk (INE Municipio Code -> Municipio Name) von Wikipedia holen
# Quelle: https://es.wikipedia.org/wiki/Anexo:Municipios_de_Bolivia
# (wird via rvest als Tabelle eingelesen)
wiki_url <- "https://es.wikipedia.org/wiki/Anexo:Municipios_de_Bolivia"
tables <- read_html(wiki_url) %>% html_table(fill = TRUE)
# Wikipedia-Seite enthält i.d.R. eine große Tabelle mit Spalten wie:
# "Código INE" / "Código", "Municipio" o.ä.
# Wir suchen die Tabelle, die eine Code-Spalte hat.
pick_idx <- which.max(sapply(tables, function(x) sum(grepl("010101|020101|030101|Código", paste(names(x), collapse=" "), ignore.case = TRUE))))
mun_table <- tables[[pick_idx]]
# Spaltennamen vereinheitlichen (robust)
names(mun_table) <- tolower(names(mun_table))
# Versuche Code- und Name-Spalte zu identifizieren
code_col <- names(mun_table)[grepl("c[oó]d", names(mun_table), ignore.case = TRUE)][1]
name_col <- names(mun_table)[grepl("municip", names(mun_table), ignore.case = TRUE)][1]
stopifnot(!is.na(code_col), !is.na(name_col))
crosswalk <- mun_table %>%
transmute(
Domain = gsub("\\D", "", as.character(.data[[code_col]])),
muni_name = as.character(.data[[name_col]])
) %>%
filter(Domain != "", !is.na(muni_name)) %>%
distinct() %>%
mutate(
name_key = stri_trans_general(toupper(trimws(muni_name)), "Latin-ASCII")
)
# 3) SAE -> Name via Crosswalk
sae_named <- sae_res %>%
left_join(crosswalk[, c("Domain", "name_key")], by = "Domain")
# Check: wie viele Domains haben jetzt einen Namen?
sum(!is.na(sae_named$name_key))
# 4) Join mit Shapefile über normalisierte Namen
map_df <- bol_muni %>%
left_join(sae_named[, c("name_key", "sae")], by = "name_key")
# Check: wie viele Shapes haben jetzt SAE?
sum(!is.na(map_df$sae))
# 5) Plot
ggplot(map_df) +
geom_sf(aes(fill = sae), color = NA) +
scale_fill_viridis_c(na.value = "grey90") +
labs(
title = "Bolivien – Fay–Herriot SAE (Municipios)",
subtitle = "Crosswalk Code→Name aus Wikipedia; Join via Municipio-Name",
fill = "FH"
) +
theme_minimal()
install.packages("rvest")   # nur einmal nötig
library(rvest)
#install.packages("rvest")   # nur einmal nötig
#library(rvest)
tables <- read_html(wiki_url) %>% html_table(fill = TRUE)
# Wikipedia-Seite enthält i.d.R. eine große Tabelle mit Spalten wie:
# "Código INE" / "Código", "Municipio" o.ä.
# Wir suchen die Tabelle, die eine Code-Spalte hat.
pick_idx <- which.max(sapply(tables, function(x) sum(grepl("010101|020101|030101|Código", paste(names(x), collapse=" "), ignore.case = TRUE))))
mun_table <- tables[[pick_idx]]
# Spaltennamen vereinheitlichen (robust)
names(mun_table) <- tolower(names(mun_table))
# Versuche Code- und Name-Spalte zu identifizieren
code_col <- names(mun_table)[grepl("c[oó]d", names(mun_table), ignore.case = TRUE)][1]
name_col <- names(mun_table)[grepl("municip", names(mun_table), ignore.case = TRUE)][1]
stopifnot(!is.na(code_col), !is.na(name_col))
#Tabelle überprüfen
library(rvest)
library(dplyr)
wiki_url <- "https://es.wikipedia.org/wiki/Anexo:Municipios_de_Bolivia"
tables <- read_html(wiki_url) %>% html_table(fill = TRUE)
length(tables)
names(tables[[1]])
head(tables[[1]])
names(tables[[2]])
head(tables[[2]])
names(tables[[3]])
# 1) Wikipedia-Tabelle (INE-Code -> Municipio-Name)
wiki_url <- "https://es.wikipedia.org/wiki/Anexo:Municipios_de_Bolivia"
tables <- read_html(wiki_url) %>% html_table(fill = TRUE)
mun_table <- tables[[1]]  # diese ist die richtige
crosswalk <- mun_table %>%
transmute(
Domain = as.character(`Código INE`),
muni_name = as.character(Nombre)
) %>%
mutate(
name_key = stri_trans_general(toupper(trimws(muni_name)), "Latin-ASCII")
) %>%
distinct(Domain, name_key)
# 2) SAE-Ergebnisse vorbereiten (Domain + FH)
# res_df hat: Domain, FH, Direct, ...
sae_res <- res_df %>%
transmute(
Domain = as.character(Domain),
sae = as.numeric(FH)
) %>%
filter(Domain != "0", Domain != "999999")  # Sondercodes raus
# 3) Join: Shape (name_3) -> Wikipedia (Domain) -> SAE
map_df <- bol_muni %>%
left_join(crosswalk, by = "name_key") %>%
left_join(sae_res, by = "Domain")
# Check: wie viele Municipios haben nun SAE?
sum(!is.na(map_df$sae))
# 4) Plot
ggplot(map_df) +
geom_sf(aes(fill = sae), color = NA) +
scale_fill_viridis_c(na.value = "grey90") +
labs(
title = "Bolivien – Fay–Herriot Small Area Estimation (Municipios)",
subtitle = "Join über Municipio-Namen (GADM Shape) + INE-Codes (Wikipedia)",
fill = "FH-Schätzer"
) +
theme_minimal()
# Wikipedia Crosswalk (INE-Code -> Municipio-Name)
wiki_url <- "https://es.wikipedia.org/wiki/Anexo:Municipios_de_Bolivia"
tables <- read_html(wiki_url) %>% html_table(fill = TRUE)
mun_table <- tables[[1]]
crosswalk <- mun_table %>%
transmute(
Domain = as.character(`Código INE`),
muni_name = as.character(Nombre)
) %>%
mutate(
name_key = stri_trans_general(toupper(trimws(muni_name)), "Latin-ASCII")
) %>%
distinct(Domain, name_key)
# SAE results: (Domain + Direct + FH)
res_for_map <- res_df %>%
transmute(
Domain = as.character(Domain),
direct = as.numeric(Direct),
fh = as.numeric(FH)
) %>%
filter(Domain != "0", Domain != "999999")
# Join: shape -> (Domain) -> results
map_df <- bol_muni %>%
left_join(crosswalk, by = "name_key") %>%
left_join(res_for_map, by = "Domain")
# Check matching
cat("Matched FH:", sum(!is.na(map_df$fh)), "out of", nrow(map_df), "\n")
cat("Matched Direct:", sum(!is.na(map_df$direct)), "out of", nrow(map_df), "\n")
# --- Plot 1: Direct ------------------------------------------------------
p_direct <- ggplot(map_df) +
geom_sf(aes(fill = direct), color = NA) +
scale_fill_viridis_c(na.value = "grey90") +
labs(
title = "Bolivien – Direct Estimates (Municipios)",
fill = "Direct"
) +
theme_minimal()
# --- Plot 2: Fay–Herriot SAE --------------------------------------------
p_fh <- ggplot(map_df) +
geom_sf(aes(fill = fh), color = NA) +
scale_fill_viridis_c(na.value = "grey90") +
labs(
title = "Bolivien – Fay–Herriot SAE (Municipios)",
fill = "FH"
) +
theme_minimal()
# Anzeigen
p_direct
p_fh
# --- Plot 3: Side-by-side (Direct vs FH) --------------------------------
# (funktioniert ohne extra packages via facetting, wir pivotieren long)
map_long <- map_df %>%
st_drop_geometry() %>%
select(name_key, direct, fh) %>%
tidyr::pivot_longer(cols = c(direct, fh), names_to = "type", values_to = "value") %>%
left_join(map_df %>% select(name_key, geometry), by = "name_key") %>%
st_as_sf()
p_compare <- ggplot(map_long) +
geom_sf(aes(fill = value), color = NA) +
facet_wrap(~ type, ncol = 2, labeller = as_labeller(c(direct = "Direct", fh = "Fay–Herriot"))) +
scale_fill_viridis_c(na.value = "grey90") +
labs(
title = "Vergleich: Direct vs Fay–Herriot (Municipios)",
fill = "Wert"
) +
theme_minimal()
